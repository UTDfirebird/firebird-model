# -*- coding: utf-8 -*-
"""DistilBERTModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SO3uzrbY7nnMJC8G-pjERVzAPPoSm6oS
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
from torch.utils.data import DataLoader

# define dataset paths (make sure they exist in Google Drive)
baseDir = "/content/drive/MyDrive/Model Development/ProcessedTensors/"
trainPath = os.path.join(baseDir, "ecuador_earthquake_2016_processed_train.pt")  # change this if using another dataset
valPath = os.path.join(baseDir, "ecuador_earthquake_2016_processed_val.pt")

# load the datasets
trainData = torch.load(trainPath)
valData = torch.load(valPath)

# define batch size
batch_size = 16  # adjust this based on your GPU memory

# create DataLoaders for training & validation
trainLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True)
valLoader = DataLoader(valData, batch_size=batch_size, shuffle=False)

# print dataset sizes
print(f"Training Batches: {len(trainLoader)}, Validation Batches: {len(valLoader)}")

from transformers import DistilBertForSequenceClassification

# define number of classes (adjust if needed)
num_labels = 2  # change this if you have more classes

# load DistilBERT with a classification head
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=num_labels)

# move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

print("Model loaded and moved to:", device)

import torch

# check if GPU is available
if torch.cuda.is_available():
    device = torch.device("cuda")
    model.to(device)
    print("Model moved to GPU:", torch.cuda.get_device_name(0))
else:
    print("No GPU found, training will be on CPU.")